---
title: "Baseline analysis of the PRULO registry"
author: "Corey Scholes"
affiliation: "EBM Analytics"
version: 3.0
type: "website"
number-sections: true
number-depth: 3
date: "2024-Aug-26"
date-modified: "2025-Apr-5"

bibliography: BasePRULO references.bib


editor:
  visual
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
  docx: 
    toc: true
    number-sections: true
    toc-depth: 2  
execute: 
  echo: true
  warning: false
  message: false
---

# Introduction

The following analysis is intended as a companion supplementary file to the [manuscript](https://onedrive.live.com/edit?id=A657866856217BF1!10470&resid=A657866856217BF1!10470&ithint=file%2Cdocx&authkey=!AO4TOxwaFGlAZGc&wdo=2&cid=a657866856217bf1) for this project. The dataset is derived from the PRULO registry snapshot and live tables. A protocol has been previously prepared for the registry [@scholes2023].

## Reporting

The study was reported according to the RECORD guidelines [@benchimol2015] and companion checklist.

The analysis was conducted in RStudio IDE (RStudio 2024.12.0+467 "Kousa Dogwood" Release) using *Rbase*, *quarto* and attached packages to perform the following;

-   Data import and preparation

-   Sample selection

-   Describe and address missingness

-   Data manipulation, modelling and visualisation of;

    -   Patient characteristics

    -   Pathology characteristics (diagnosis)

    -   Patient reported outcomes

-   Publish to posit connect for dissemination

## Preparation

Packages were loaded initially with *pacman* package. Citations were applied to each library at first use in the text.

```{r, load-pkgs}

if (!require("pacman")) install.packages("pacman")
pacman::p_load(# Load required packages
  "ggdag",
  "ggmap",
  "geosphere",
  "dplyr",
  "flextable",
  "litedown",
  "grateful",
  "modelsummary",
  "quantreg",
  "readr",
  "knitr",
  "cardx",
  "forcats",
  "gargle",
  "googledrive",
  "googlesheets4",
  "openxlsx2",
  "tidyverse",
  "tidymodels",
  "lubridate",
  "consort",
  "gtsummary",
  "survival",
  "ggplot2",
  "ggdist",
  "ggfortify",
  "mice",
  "marginaleffects",
  "naniar",
  "quantreg",
  "broom",
  "epoxy",
  "broom.helpers",
  "stringr"
  )
  
  
```

```{r}
#| label: tbl-pkgcite
#| echo: false
#| tbl-cap: Summary of package usage and citations

pkgs <- grateful::cite_packages(
  dependencies = FALSE,
  output = "table", 
  out.dir = ".",
  cite.tidyverse = FALSE,
  include.RStudio = FALSE,
  bib.file = "grateful-refs"
  )

knitr::kable(
  pkgs
)



```

The packages drawn on to produce the following report are summarised in @tbl-pkgcite.

## Authorisations

Access to PRULO datasets was pre-authorised using the *gargle* package and *googledrive*.

```{r}
#| label: auth1
#| echo: false

googledrive::drive_deauth()

# Set the cache location
options(gargle_oauth_cache = ".secrets")

# Use the saved token for non-interactive auth
googledrive::drive_auth(
  email = "cscholes@ebma.com.au", 
  cache = ".secrets"
  )
```

```{r}
#| label: auth2
#| echo: false

options(
  gargle_oauth_cache = ".secrets",
  gargle_oauth_email = TRUE
)

drive_auth(cache = ".secrets", email = TRUE)
```

## Functions for Processing

A function was generated to retrieve files using the *googledrive* package, to call on later in the analysis for processing data imports.

```{r}

#| label: folder
#| echo: false

base_folder_id1 <- "1og1hWKEXFcy8v8pLSzA_Ii767bbCe_EK"

```

```{r}
get_specific_snapshot <- function(folder_name, base_folder_id = base_folder_id1) {
  tryCatch({
    # Check if the folder exists in the base directory
    folder <- googledrive::drive_ls(as_id(base_folder_id), pattern = paste0("^", folder_name, "$"))
    
    if(nrow(folder) == 0) {
      stop(paste("Folder", folder_name, "not found"))
    }
    
    # Find the snapshot file in the specified folder
    snapshot_file <- googledrive::drive_ls(
      folder$id, 
      pattern = "Registry data snapshot\\.xlsx$"
    )
    
    if(nrow(snapshot_file) == 0) {
      stop("No snapshot file found in specified folder")
    }
    
    # Return both pieces of information as a list
    return(list(
      snapshot = snapshot_file,
      folder_name = folder$name
    ))
    
  }, error = function(e) {
    stop(paste("Error finding specified snapshot:", e$message))
  })
}
```



## Analysis Aim

*Retrieved from the manuscript (edits in italics);*

Optimising postoperative outcomes is dependent on appropriate patient selection. Previous studies have highlighted key patient characteristics which affect post operative outcomes. The aim of this study is to *describe* the *baseline* characteristics of patients that present to a regional practice with shoulder pathology, an*d* determine any differences (*when adjusted for covariates*) in PROMs responses *between* these groups at baseline preoperatively.

## Analysis Hypotheses

When adjusted for covariates, *Glenohumeral Instability* will demonstrate significantly increased pain and dysfunction at baseline compared to *Rotator Cuff* and *General* pathology cohorts.

# Methods

## RECORD \[4\] - Study Design

Subgroup analysis of a clinical registry embedded into private practice. Observational, cross-sectional design.

## Data Import and Preparation

Data was retrieved using *googlesheets4* to retrieve live database tables. Source files were specified and stored as global variables to call on in further functions.

```{r}
#| label: live-table
#| echo: false

SheetIDs <- list(
DbSS = "https://docs.google.com/spreadsheets/d/1zyFuf0Wmij13ELTYNmdi_BprF8hU4QSCPsNZ0EYRXzo/edit",
ImplantSS = "https://docs.google.com/spreadsheets/d/1MvT00sc8FzH5SXEi-yzEgW1H1ao3AOoakKqpg7UkxW4/edit",
#AcctSS ="https://docs.google.com/spreadsheets/d/1zyFuf0Wmij13ELTYNmdi_BprF8hU4QSCPsNZ0EYRXzo/edit",
SurgicalGapSS = "https://docs.google.com/spreadsheets/d/1qVGc27EEevETq3OvJsJ0UUMKhPG07H7J209ZCHN8Ww8/edit"
)



```

```{r}
#| label: read-tables

# Authenticate for sheets using the same token
gs4_auth(token = drive_token())



ComplicTable <- googlesheets4::read_sheet(
  ss = SheetIDs$DbSS,
  sheet = "Complications", 
  col_names = TRUE, 
  col_types = "tcccDccD"
  )

ImplantTable <- googlesheets4::range_read(
  ss = SheetIDs$ImplantSS,
  sheet = "Healix", 
  range = "F1:I",
  col_names = TRUE, 
  col_types = "nccc"
  )

# AcctData <- googlesheets4::range_read(
#   ss = SheetIDs$AcctSS,
#   sheet = "AcctType2015", 
#   range = "A1:G",
#   col_names = TRUE, 
#   col_types = "ccccDcc"
#   )

#To match to acctData
PatientTable <- googlesheets4::range_read(
  ss = SheetIDs$DbSS,
  sheet = "Patient", 
  range = "A10:N",
  col_names = FALSE, 
  col_types = "DccccDcccDcicc"
  )


Patient_Col <- c(
  "PatientCreationDate",
  "PatientID",
  "LastName",	
  "FirstName",	
  "AlternateID",	
  "DateOfBirth",	
  "Sex",	
  "RegistryStatus",	
  "RegistryStatusNotes",	
  "DateRegistryStatus",	
  "NotificationMethod",	
  "NoTreatmentRECORDs",	
  "Email",	
  "Phone"
)

colnames(PatientTable) <- Patient_Col


```

A static registry snapshot was retrieved using the pre-specified function (see *Functions for Processing)* and formatted using *openxlsx* based on the fixed date of preparation of the snapshot (30-Jun-2024) and using *tidyverse* syntax and associated packages (*dplyr, lubridate*). Date columns were prepared for further analysis using *lubridate*.

```{r}

# Authenticate for sheets using the same token
gs4_auth(token = drive_token())

# To get a snapshot from a specific folder (e.g., "20230415")
specific_snapshot <- get_specific_snapshot("20250331")


```

```{r}

temp_file1 <- tempfile(fileext = ".xlsx")
drive_download(
  file = specific_snapshot$snapshot$id,
  path = temp_file1,
  overwrite = TRUE
)

# Correction to reset back to excel origin
DaysDiff <- as.numeric(as.duration(interval(ymd("1899-12-30"), ymd("1970-01-01"))),"days")

SnapshotGen <- openxlsx2::read_xlsx(
  temp_file1,
  sheet = "ShoulderGeneral",
  colNames = TRUE,
  detectDates = TRUE
  ) |> dplyr::mutate(
    Cohort = "General",
    across(starts_with("IC"),as.character)
  )

SnapshotRC <- openxlsx2::read_xlsx(
  temp_file1,
  sheet = "RotatorCuff",
  colNames = TRUE,
  detectDates = TRUE
  ) |> dplyr::mutate(
    Cohort = "Rotator Cuff",
    across(starts_with("IC"),as.character)
  )

SnapshotGH <- openxlsx2::read_xlsx(
  temp_file1,
  sheet = "GlenohumeralInstability",
  colNames = TRUE,
  detectDates = TRUE
  ) |> dplyr::mutate(
    Cohort = "Glenohumeral Instability",
    across(starts_with("IC"),as.character)
  )


STROBEInput <- openxlsx2::read_xlsx(
  temp_file1,
  sheet = "Strobe_Input",
  colNames = TRUE,
  detectDates = TRUE
  )

```

Dataframes were combined into one for further analysis.

```{r}
#| label:  Slice-stack-1
#| code-summary: "Line up input frames"


SnapshotComb <- SnapshotRC |> dplyr::bind_rows(
  dplyr::select(SnapshotGH, -ExternalStudyTag)
  ) |> bind_rows(
    dplyr::select(
      SnapshotGen,
      -ExternalStudyTag)
    ) |> dplyr::mutate(
    PatientID = stringr::str_split_i(TreatmentID,"\\.",1)
  ) |> relocate(
    PatientID, .before = TreatmentID
  ) |> mutate(
    CombID = paste0(PatientID,".",AffectedSide)
  ) |> relocate(
    CombID, .after = TreatmentID
  ) |> relocate(
    Cohort, .before = EligibleAtPreop
  )

```

```{r}
#| echo: false

## Authenticate for sheets using the same token
gs4_auth(token = drive_token())

AcctNewFile = "1Xo58d7b6NJOVIxPbYmlCrDRiVGhmKan8"



```

```{r}

#Read in full text file
#
temp_file2 <- tempfile(fileext = ".txt")
drive_download(
  file = as_id(AcctNewFile),
  path = temp_file2,
  overwrite = TRUE
)

AcctDataNew <- readr::read_tsv(
  file = temp_file2,
  col_names = TRUE,
  #trim_ws = TRUE,
  col_types = list(
  Id = "c",
  AccountType = "c",
  Surname = "c",
  FirstName = "c",
  DOB = col_date(format = "%d/%m/%Y"),
  UsualProvider = "c",
  HealthFundName = "c",
  HccPensionNum = "c",
  DvaNum = "c"
),
col_select = c(
  AlternateID = Id,
  LastName = Surname,
  FirstName,
  DateOfBirth = DOB,
  HealthFundName
  )
) |> dplyr::mutate(
  DateOfBirth2 = as.numeric(DateOfBirth),
  HealthFund2 = str_to_lower(HealthFundName),
  LastName = stringr::str_to_title(LastName)
) |> unite(
  col = "CombID",
  sep = ".",
  c("FirstName","LastName","DateOfBirth2"),
  remove = FALSE
) |> mutate(
  CombID = stringr::str_squish(CombID),
    AccountType2 = case_when(
      stringr::str_detect(HealthFund2,"nil|uninsured") == TRUE ~ "Uninsured",
      stringr::str_detect(HealthFund2,"fund|pty|limit*|nib|hcf|bupa|medibank|hbf|ahm|health|hba|a.u|^unity$|cbhs|unity|^yes$")  == TRUE ~ "Private",
      stringr::str_detect(HealthFund2,"dva|vaff|vet|aff|def")  == TRUE ~ "DVA",
      stringr::str_detect(HealthFund2,"work*|wc|w//c*")  == TRUE ~ "WorkCover",
      stringr::str_detect(HealthFund2,"^tac$")  == TRUE ~ "TAC",
      stringr::str_detect(HealthFund2,"sf|self")  == TRUE ~ "SelfFund",
      )
    ) |> left_join(
  PatientTable |> dplyr::select(
  PatientID,
  AlternateID
  ),
  by = "AlternateID"
  ) |> dplyr::filter(
  PatientID %in% SnapshotComb$PatientID
)

```

## RECORD \[5\] - Setting

The PRULO registry is based in a regional private practice for upper limb orthopaedics [@scholes2023].

```{epoxy}

The registry has {nrow(SnapshotComb)} treatment RECORDs with the first patient enrolled {format(min(SnapshotComb$DateTreatmentRecordCreation, na.rm = TRUE), format = "%d %B %Y")} and the final treatment RECORD created {format(max(SnapshotComb$DateTreatmentRecordCreation, na.rm = TRUE), format = "%d %B %Y")}.The registry snapshot was extracted on {format(ymd("20250331"), format = "%d %B %Y")}. Patients are followed for up to 2 years after surgery to capture treatment outcomes and patient-reported outcome measures (PROMs). 

```

## RECORD \[6\] Participants

### RECORD \[6.1\] Sample selection

Identify cases receiving the suture of interest. Cases were identified by SKUs identified from the SKU database maintained as part of implant tracking within the registry. Cases were not restricted by available follow up.

Inclusion criteria;

-   Case is eligible for baseline PROMs collection prior to treatment

Data manipulation (add columns and filter tables based on column values) was performed with *tidyverse* and converted to display format using *gt*.

A dataframe was prepared to generate a flow chart of RECORD retrieval, screening and patient follow up within the sample of interest.

```{r}

#| label: Consort-Diagram
#| code-summary: "CONSORT|STROBE"

# Inclusion
# - Eligible for Preop
# - Not an Archived RECORD prior to treatment
# After "induction"
# - Patient withdraws consent
# 
CurrentDate <- as.character("20250331")


STROBEFlow <- STROBEInput |> dplyr::filter(
  !is.na(TreatmentID)
) |> dplyr::left_join(
  SnapshotComb |> dplyr::select(
    TreatmentID,
    CombID,
    DateInitialExamination,
    TreatmentStatusNotes,
    EligibleAtPreop
  ),
  by = "TreatmentID"
) |> dplyr::mutate(
  EligibleAtPreop2 = case_when(
    is.na(EligibleAtPreop) ~ "No",
    .default = EligibleAtPreop
  ),
  DateDiff1 = DateTreatmentRecordCreation - DateTreatment,
  exclusion1 = case_when(
    EligibleAtPreop2 == "No" & stringr::str_detect(RegistryStatus, "Opt-out") & DateRegistryStatus < DateTreatment ~ "Patient opt-out",
    TreatmentStatus == "Archived" & EligibleAtPreop2 == "No" ~ "Not eligible for registry",
    TreatmentStatus != "Archived" & EligibleAtPreop2 == "No" & DateDiff1 >= 0 ~ "Retrospective RECORD",
    EligibleAtPreop2 == "No" ~ "Unknown",
    .default = NA_character_
  ), 
  induction = if_else(
    is.na(exclusion1),
    TreatmentID,
    NA_character_
  )
) |> group_by(CombID) |> mutate(
  CombIDn = row_number(DateTreatment)
) |> ungroup() |> dplyr::mutate(
  exclusion2 = if_else(
    is.na(exclusion1) & CombIDn > 1,
    "Non-index treatment",
    NA_character_
  ),
  subjid_dosed = if_else(
    is.na(exclusion2) & is.na(exclusion1),
    TreatmentID,
    NA_character_
  )
) |> dplyr::rename(
  trialno = "TreatmentID",
  arm3 = "RegistryCohortName"
)


```

The combined snapshot dataframe was filtered using the results of the STROBE flowchart dataframe and the sample of interest retrieved.

```{r}
#| label: slice-stack-3
#| code-summary: "line up input frames"

Mastersheet1 <- SnapshotComb |> dplyr::filter(
  TreatmentID %in% STROBEFlow$subjid_dosed
) |> dplyr::mutate(
  Sex2 = case_when(
      Sex == "F" ~ "Female",
      Sex == "M" ~ "Male"),
)

```

```{epoxy}

Of the {nrow(Mastersheet1)} RECORDs in the mastersheet, {nrow(Mastersheet1 |> filter(grepl("opt",RegistryStatus,ignore.case = TRUE)))} treatment RECORDs had withdrawn consent for data inclusion and {nrow(Mastersheet1 |> filter(grepl("prom",RegistryStatus,ignore.case = TRUE)))} had withdrawn participation in PROMs after enrolment. 

```

### RECORD \[6.2\] Algorithm validation

RECORD selection code was cross-checked by manual RECORD checking within the registry snapshot for a subset (N = 10) of cases.

### RECORD \[6.3\] Data linkage

No data linkage was utilised for this analysis.

## RECORD \[7\] Variables

The analysis variable set was based on the [core dataset](https://docs.google.com/spreadsheets/d/1fTzpU5WDcqe-y-TldJ7lwhNLRleUifWaWwcvGYU-GnM/edit?gid=2114241611#gid=2114241611) of the registry.

The outcome variables in this analysis were the QuickDASH Total score and the EQ5D-5L Index score. The *Quick*DASH is the 11-item shortened version of a questionnaire assessing activity limitations and symptoms in people with musculoskeletal disorders of the upper limb [@beaton2005] which has similar measurement properties to the full 30-item DASH [@gummesson2006], particularly for patients undergoing RCR [@macdermid2015]. The QuickDASH assesses a variety of activities including work, sports, and social activities. A minimum of 10 out of 11 items are required for calculation of a *Quick*Dash score, which ranges from 0 (no disability) to 100 (most severe disability). The MCID score for the QuickDASH is 15.91 points [@franchignoni2014].

The EQ-5D 5L is a generic tool for measuring quality of life, describing health in terms of five dimensions: mobility, self-care, usual activities, pain and discomfort, and anxiety and depression [@conner-spady2015]. Patients respond to each item on a 5 level range of severity, following the format of "no problems", "slight problems", "moderate problems", "severe problems", and "unable to or extreme problems". The EQ-5D 5L has been shown to have good validity and discriminatory power in a range of pathologies [@janssen2012]. The MCID is approximately 0.074 [@walters2005].

## RECORD \[8\] Data sources

Data was sourced directly from the PRULO clinical registry [@scholes2023]. Patient and treatment information were entered into the database through the registry interface and compiled into a data cube (snapshot) every quarter. The snapshot used for analysis was extracted `{r} format(lubridate::ymd(CurrentDate), format = "%d %B %Y")`.

## RECORD \[9\] Bias

For a discussion of biases in the context of the clinical registry utilised for this analysis, refer to [@scholes2023]. Specific to this analysis, the following considerations were noted;

::: {#tbl-bias}
| Bias | Definition | Source | Mitigation |
|------------------|------------------|------------------|------------------|
| Misclassification | Treatment RECORD labelled into incorrect cohort. PROMs package not aligned to clinical presentation | [@benchimol2015] | Clinical notes reviewed by experienced reviewer and matched to ICD10 code by definition. |
| Confounder | An variable of interest and a target outcome simultaneously influenced by a third variable | [@tennant2020] | PROMs analysis incorporated adjustment for age and sex |
| Missing data | The absence of a data value where a treatment RECORD is eligible to have a data value collected | [@carroll2020] | Multiple imputation utilised |
| Prevalent user | Follow-up starts after eligible individuals have started the treatment. The follow-up time is left-truncated | [@nguyen2021] | Eligibility and enrollment is performed prior to treatment offering for any patient or new presentation. Index procedures identified for analysis are followed prior to surgery occurring. |
| Selection | Treatments are selected based on post-treatment criteria | [@nguyen2021] | Unable to be mitigated fully - RECORDs are identified by presence of hardware code associated with suture of interest |
| Immortal time | Individuals need to meet eligibility criteria that can only be assessed after follow-up has started | [@nguyen2021] | Patients enrolled at time of diagnosis |
| Pseudoreplication | Analyse data while ignoring dependency between observations. Inadequate model specification. | [@davies2015; @lazic2010] | Cluster for patient in survival (all-cause failure and retear). Remove non-index RECORDs from dataset |

Biases in analysis of observational cohort of a clinical registry
:::

## RECORD \[10\] Sample size

Sample size was derived from the available RECORDs of the Registry at the time of analysis.

## RECORD \[11\] Quantitative variables

### Geocoding postcode of residence

Patient residence postcodes were geocoded using the google map api via the *ggmap* package, which was also used to plot the case volume by postcode in the areas surrounding the clinic. The straight line distance from the centre of the postcode, indicated by longitude and latitude coordinates was calculated from the centre of Geelong using the haversine method from the *geosphere* package, which assumes the earth is spherical and ignores ellipsoidal effects.

```{r}
PostCodeSum <- Mastersheet1 |> group_by(
  Postcode
) |> summarise(
  PresentFreq = n()
) |> arrange(
  desc(PresentFreq)
) |> filter(
  !is.na(Postcode)
)
```

```{r}
#| echo: false
#| eval: false

register_google(key = "AIzaSyC4KUNAiSMIvh5Qm4u1PbHY23CHnCII1Hk", write = TRUE)

```

```{r}


PostCodeFilt <- PostCodeSum |> dplyr::select(Postcode) |> filter(!(is.na(Postcode)|Postcode == "armstr"))

Postcodes <- paste(PostCodeFilt$Postcode, sep = ",")

PostCodeCoord <- ggmap::geocode(paste(Postcodes,"Australia"),
               output = "latlona",
               source = "google")

```

```{r}

# Geelong coordinates
geelong_coords <- c(lon = 144.3598, lat = -38.1493)

PostCodeCoord2 <- PostCodeCoord |>
  mutate(
    Postcode = str_extract(address, "\\d+"),
    # Create a matrix of longitude and latitude for each postcode
    Coords = purrr::map2(lon, lat, ~ matrix(c(.x, .y), ncol = 2)),
    # Calculate distance using distHaversine
    StraightDist = purrr::map_dbl(Coords, ~ distHaversine(.x, geelong_coords))/1000
  ) |> filter(
    !is.na(Postcode)
  )

```

```{r}
PostCodeSum1 <- left_join(
  PostCodeSum |> filter(!(is.na(Postcode)|Postcode == "armstr")),
  PostCodeCoord2,
by = "Postcode"
)
```

```{r}
#| label: fig-geomap
#| fig-cap: "Density map of patient residential postcode."

hdf <- ggmap::get_map("geelong, australia")

#Create the heatmap
Geelong <- ggmap::get_map(
  "Geelong, Australia",
  zoom = 9,
  scale = "auto",
  source = "google"
  )

circle_scale_amt <- 0.04

Map1 <- ggmap(
  Geelong,
  extent = "device"
  )

Map2 <- Map1 + geom_point(aes(x = lon, y = lat, col = "blue"), 
                          data = PostCodeSum1, 
                          size=PostCodeSum1$PresentFreq*circle_scale_amt, 
                          alpha = .5
                          ) +
  scale_size_continuous(range=range(PostCodeSum1$PresentFreq)) +
    theme(legend.position="none") +
  coord_quickmap()

knitr::knit_print(Map2)
```

Data was read in from database table to determine account type.

```{r}

PatientTable1 <- PatientTable |> filter(
  !is.na(PatientCreationDate) & !grepl("\\btest\\b",LastName,ignore.case = TRUE) & !is.na(DateOfBirth)
) |> mutate(
  DateOfBirth2 = as.numeric(as.duration(interval(ymd("1900-01-01"), ymd(DateOfBirth))),"days")
) |> unite(
  col = "TempID",
  sep = ".",
  c("FirstName","LastName","DateOfBirth2"),
  remove = FALSE
)

```

### Account Type

```{r}
# Repeat process for acctData table

AcctData1 <- AcctDataNew |> filter(
  !grepl("\\btest\\b",LastName,ignore.case = TRUE) & !is.na(DateOfBirth)
) |> mutate(
  DateOfBirth2 = as.numeric(as.duration(interval(ymd("1900-01-01"), ymd(DateOfBirth))),"days"),
  HealthFund2 = str_to_lower(HealthFundName)
) |> unite(
col = "TempID",
sep = ".",
c("FirstName","LastName","DateOfBirth2"),
remove = FALSE
) |> left_join(
  PatientTable1 |> dplyr::select(
    AlternateID,
    PatientID,
    TempID
    ),
  by = "TempID"
  ) |> mutate(
    AccountType2 = case_when(
      stringr::str_detect(HealthFund2,"nil|uninsured") ~ "Uninsured",
      stringr::str_detect(HealthFund2,"fund|pty|limit*|nib|hcf|bupa|medibank|hbf|ahm|health|hba|a.u|^unity$|cbhs|unity|^yes$|pri|mbs") ~ "Private",
      stringr::str_detect(HealthFund2,"workcover|\\bwc\\b|w//c*|cgu") ~ "WorkCover",
      stringr::str_detect(HealthFund2,"dva|vaff|vet*|aff*|def*") ~ "DVA",
      stringr::str_detect(HealthFund2,"^tac$") ~ "TAC",
      stringr::str_detect(HealthFund2,"sf|self") ~ "SelfFund",
      .default = "Unknown"
      )
    )

```

```{r}

Mastersheet2 <- Mastersheet1 |> left_join(
  PatientTable1 |> dplyr::select(
    FirstName,
    LastName,
    PatientID,
    DateOfBirth2
  ),
  by = "PatientID"
)  |> unite(
  col = "TempID",
  sep = ".",
  c("FirstName","LastName","DateOfBirth2"),
  remove = FALSE
) |> left_join(AcctData1 |> dplyr::select(
  AccountType2,
  HealthFund2,
  TempID),
  by = "TempID"
  ) |> left_join(
  PostCodeSum1 |> dplyr::select(
    Postcode,
    StraightDist
  ),
  by = "Postcode"
)


```

The dataframes containing patient-reported outcomes data were manipulated to reduce the columns to those relevant for PROMs analysis and to filter based on eligibility for the baseline time point.

### Rescore SMCQ

The self-reported medical comorbidities questionnaire [@sangha2003] was manually rescored within the analysis.

```{r}

SMCQScore <- Mastersheet2 |> dplyr::select(
  TreatmentID,
  ComorbHeartDisease_Preop:ComorbBloodClots_Preop
) |> filter(
  !if_all(ComorbHeartDisease_Preop:ComorbBloodClots_Preop, is.na)
) |>
  mutate(
    across(ComorbHeartDisease_Preop:ComorbBloodClots_Preop, 
           ~ case_when(
             str_detect(., "(?i)(do.not)") ~ 0,
             str_detect(., "(?i)have") ~ 1,
             str_detect(., "(?i)treatment") ~ 2,
             str_detect(., "(?i)limits") ~ 3,
             TRUE ~ NA_real_
           ), 
           .names = "{.col}_Score")
  ) |>
  mutate(
   SMCQTotal = rowSums(across(ends_with("_Score")), na.rm = TRUE)
  )

# ComorbHeartDisease_Preop
# ComorbHighBloodPressure_Preop     
# ComorbLungDisease_Preop         
# ComorbDiabetes_Preop              
# ComorbUlcer_Preop                
# ComorbKidneyDisease_Preop        
# ComorbLiverDisease_Preop           
# ComorbAnemia_Preop             
# ComorbCancer_Preop              
# ComorbAnxietyDepression_Preop    
# ComorbOsteoArthritis_Preop         
# ComorbBackPain_Preop           
# ComorbRheumatoidArthritis_Preop
# ComorbBloodClots_Preop

```

Return SMCQ total score to Snapshot dataframe

```{r}

Mastersheet3 <- left_join(
  Mastersheet2,
    SMCQScore |> dplyr::select(
      TreatmentID,
      SMCQTotal
    ),
    by = "TreatmentID"
  ) |> filter(
    Sex != "N"
  )



```

## RECORD \[12\] Statistical methods

A number of analytical techniques were employed to i) clean the data inputs as well as ii) evaluate missingness in the dataset and iii) complete the descriptive analysis of;

-   Patient characteristics

-   Pathology details

-   Patient-reported outcomes

### RECORD \[12.1\] Access to population

The registry system represents all cases presenting to the rooms of a surgical group within Geelong, Australia using the implant of interest from the inception of the clinical registry to the analysis date. All reviewed charts from the operating surgeons practice RECORDs (electronic medical RECORD) were entered into database and the present analysis draws data from a regular compilation of the registry RECORDs (snapshot) produced quarterly by the registry administration team.

### RECORD \[12.2\] Data cleaning methods

Diagnosis description free text fields were pre-processed to remove relational terms (stopwords) and expand abbreviations to improve clarity.

### RECORD \[12.3\] Data linkage

Not applicable

### RECORD \[12.4\] Missingness

#### Evaluation

Missingness was assessed with visualisation and table functions in the *naniar* package and compiled into figures using *patchwork*.

```{r}
#| label: fig-missing
#| fig-cap: "Missingness rates of patient characteristics and patient-reported outcomes"

# Assessing missingness from Mastersheet2

#Patient characteristics

MissFig1 <- Mastersheet3 |>
 dplyr::select(
    AgeAtInitialExam, 
    Sex2, 
    IndexSide,
    BMI,
    BilateralStatus,
    AccountType2,
    Postcode,
    SignificantComorbidities_Preop,
    QDASH_TotalScore_Preop,
    EQ5D5L_IndexScore_Preop
    ) |> rename (
      `Age at Consult` = "AgeAtInitialExam", 
    Sex = "Sex2", 
    `Affected Side` = "IndexSide",
    `Body Mass Index` = "BMI",
    `Bilateral Status` = "BilateralStatus",
    `Insurance Status` = "AccountType2",
    Comorbidities = "SignificantComorbidities_Preop",
    QuickDASH = "QDASH_TotalScore_Preop",
    EQ5D = "EQ5D5L_IndexScore_Preop"
    ) |> gg_miss_var(show_pct = TRUE)

knitr::knit_print(MissFig1)

```

### RECORD \[12.5\] Analysis

#### Regression preparation

A brief literature review was conducted to identify potential factors that should be adjusted for when assessing the effect of *Cohort* on *PROMs scores* in the present sample. It is important to adjust the relationship between the predictor (Cohort) and the outcome (PROM score) for confounders - variables that influence both the predictor and the outcome [@tennant2020]. The relationship between patient characteristics and PROMs outcomes are illustrated in Figure 2 for Rotator Cuff (Figure 2a), Glenohumeral Instability (Figure 2b) and Glenohumeral Osteoarthritis (Figure 2c).

::: {#fig-rcfactor}
(images/RC%20Factor%20Concepts%20Diagram_v2.jpg)

Summary of factors associated with outcomes from Rotator Cuff pathology and surgery
:::

::: {#fig-ghifactor}
(images/Shoulder%20Instability%20Factor%20Concepts%20Diagram%202-01.jpg)

Summary of factors associated with outcomes from Glenohumeral Instability and surgery
:::

::: {#fig-ghoafactor}
(images/OA_concepts%20map_v1.JPG)

Summary of factors associated with outcomes from Glenohumeral Osteoarthritis and surgery
:::

The important element in determining whether these factors should be considered confounders in the relationship between Registry Cohort and PROMs outcomes, is whether they are also associated with the Registry Cohort in which a patient (presentation) is allocated.

Age is associated with shoulder pathology. A study of osteoarthritis in the general population reported an increased incidence with increasing age [@kobayashi2014], others have reported similar patterns for rotator cuff tears [@tashjian2012]. The same systematic review also reported lifestyle factors (diet, activity level, smoking history) as being related to cuff tear presentation. Shoulder pathologies may also afflict the sexes in different ways, with males presenting with dislocation at over 2.5 times the rate of females to emergency departments in the US [@zacchilli2010]. Overall, it would appear that most patient characteristics would differ between registry cohorts due to the relationships between activity, disease and injury aetiology and lifestyle factors.

An input table was set up for statistical analysis with only the variables required for the models. The *ggdag* package was used to create and visualise directed acyclic graphs (in conjunction with *ggplot2*), with minimal adjustment sets to ensure correct specification of models to estimate the effect of Cohort on QuickDASH Total score and EQ5D Index score.

```{r}
#| label: fig-dag
#| fig-cap: "Directed acyclic graph of Cohort -> PROMs"

DAGPROM <- ggdag::dagify(PROMScore ~ Cohort + Age + Sex + BMI +  ComorbidBurden+ Bilateral + CompStatus + Activity + Smoke + Alcohol,
          Cohort ~ Age + Sex + BMI +  ComorbidBurden+ Bilateral + CompStatus + Activity + Smoke + Alcohol,
          ComorbidBurden ~ Age + BMI +  CompStatus + Activity + Smoke + Alcohol,
          Bilateral ~ Age,
          BMI ~ Age + Alcohol + Smoke,
          Activity ~ Age + Sex + Smoke + Alcohol + CompStatus,
          Alcohol ~ Age + ComorbidBurden,
  labels = c(
    "ComorbidBurden" = "Comorbidity Burden",
    "Smoke" = "Smoking History",
    "Alcohol" = "Alochol History",
    "Age" = "Age at\n Initial Exam",
    "Cohort" = "Registry \n group",
    "BMI" = "Body Mass\n Index",
    "Sex" = "Sex",
    "Bilateral" = "Bilateral Presentation",
    "CompStatus" = "Compensation Status"
  ),
  exposure = "Cohort",
  outcome = "PROMScore"
)

# Create a tidy version of the DAG and apply custom labels
tidy_dag1 <- ggdag::tidy_dagitty(DAGPROM, layout = "auto") |>
  dplyr::mutate(label = case_when(
    name == "ComorbidBurden" ~ "Comorbidity Burden",
    name == "Smoke" ~ "Smoking History",
    name == "Alcohol" ~ "Alochol History",
    name == "Age" ~ "Age at\n Initial Exam",
    name == "Cohort" ~ "Registry \n group",
    name == "BMI" ~ "Body Mass\n Index",
    name == "Sex" ~ "Sex",
    name == "Bilateral" ~ "Bilateral Presentation",
    name == "CompStatus" ~ "Compensation Status",
    TRUE ~ name
  ))

Figure3 <- ggplot(
  tidy_dag1, 
  aes(
    x = x, 
    y = y, 
    xend = xend, 
    yend = yend)
  ) +
  geom_dag_node(
    color = "darkblue", 
    fill = "lightblue", 
    alpha = 0.5, 
    size = 20) +
  geom_dag_text(
    aes(
      label = label
      ), 
    color = "black", 
    fontface = "bold", 
    size = 3, 
    vjust = 0.5
    ) +
  geom_dag_edges(
    edge_color = "gray50", 
    edge_width = 0.5, 
    #edge_arrow_size = 0.3
    ) +
  theme_dag(
    base_size = 12,
    base_family = "",
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white")
  ) +
  theme(
    plot.title = element_text(
      hjust = 0.5, 
      size = 16, 
      face = "bold"
      ),
    plot.margin = margin(
      20, 
      20, 
      20, 
      20
      )
  ) +
  ggtitle(
    "Directed Acyclic Graph"
    )

knitr::knit_print(Figure3)


```

```{r}
#| label: fig-adjset
#| fig-cap: "Calculated minimum adjustment set for modelling Cohort -> PROMs"

Figure4 <- ggdag_adjustment_set(
  tidy_dag1,
  text = FALSE,
  #use_labels = "label"
  exposure = "Cohort",
  outcome = "PROMScore"
  ) +
  geom_dag_node(
    color = "darkblue", 
    fill = "lightblue", 
    alpha = 0.7, 
    size = 10
  ) +
  # geom_dag_text(
  #   aes(label = label),  # Use the 'label' column directly
  #   color = "black", 
  #   fontface = "bold", 
  #   size = 3, 
  #   vjust = -1.5,  # Adjust vertical position
  #   hjust = 1.5,  # Adjust horizontal position
  #   show.legend = FALSE  # Prevent text from appearing in legend
  # ) +
  geom_dag_label_repel(
    aes(label = label, fill = adjusted),
    color = "white",
    fontface = "bold",
    size = 3,
    show.legend = FALSE,
    box.padding = unit(0.5, "lines"),  # Padding around labels
    point.padding = unit(0.5, "lines"),  # Padding around points
    nudge_y = 0.5,  # Adjust vertical nudge
    nudge_x = 0.5   # Adjust horizontal nudge
  ) +
  geom_dag_edges(
    edge_color = "gray50", 
    edge_width = 0.5
  ) +
  theme_dag(
    base_size = 10,
    base_family = "",
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white")
  ) +
  theme(
    plot.title = element_text(
      hjust = 0.5, 
      size = 10, 
      face = "bold"
    ),
    plot.margin = margin(20,20,20,20),
    legend.position = "bottom",
    legend.background = element_rect(fill = "white", color = "gray80"),
    legend.title = element_text(face = "bold")
  ) +
  ggtitle("Adjustment Set for Directed Acyclic Graph")


knitr::knit_print(Figure4)

```

Figure 4:

A summary table was generated to illustrate the status of key patient factors for inclusion into the analysis and their availability within the registry dataset (Table 2).

Table 2: Summary of potential adjustment set for *Cohort* -\> *PROMs* retrieved from the literature

|  |  |  |  |
|-------------------|------------------|------------------|------------------|
| Variable | Associated with *Cohort* | Associated with *PROMs* | Available in present dataset |
| Sex (Male) | ✅ | ✅ | ✅ |
| Age (at initial examination) | ✅ | ✅ | ✅ |
| Body mass index | ? | ✅ | ❌ |
| Comorbidity Burden | ✅ | ✅ | ✅ |
| Bilateral presentation | ✅ | ✅ | ✅ |
| Compensation status | ✅ | ✅ | ✅ |
| Activity Level | ✅ | ✅ | ✅ |
| Alcohol consumption | ? | ✅ | ✅ |
| Smoking history | ✅ | ✅ | ✅ |

#### Management

The data tables were reduced to the required columns (PROMs and adjunct columns) in preparation for multiple imputation using chained equations [@white2010] with the *mice* package. One patient with bilateral RECORDs in the sample had one field (EducationLevel_Preop) mirrored from one side RECORD to the other, where it was missing. Character fields were converted to factors and the dataset was filtered to those cases that were eligible for 12months followup.

```{r}
Mastersheet4 <- Mastersheet3 |> dplyr::select(
  TreatmentID,
  Cohort,
  TreatmentType,
  IndexSide,
  AccountType2,
  StraightDist,
  SMCQTotal,
  AgeAtInitialExam,
  Sex2,
  BilateralStatus,
  IndexSide,
  EducationLevel_Preop:ActivityLevel_Preop,
  QDASH_TotalScore_Preop,
  EQ5D5L_IndexScore_Preop
  #matches("modem", ignore.case = TRUE) & ends_with("preop", ignore.case = TRUE)
) |> mutate(
  CompStatus = if_else(str_detect(AccountType2,"Work|DVA|TAC"),"Yes","No"),
  QDASH_TotalScore_Preop = as.numeric(QDASH_TotalScore_Preop),
  EQ5D5L_IndexScore_Preop = as.numeric(EQ5D5L_IndexScore_Preop),
  across(where(is.character) & !contains("TreatmentID", ignore.case = TRUE), as.factor),
  AlcoholConsumption_Preop = forcats::fct_relevel(
    AlcoholConsumption_Preop, 
    "None",
    "Less than or equal to 2 standard drinks",
    "More than 2 standard drinks"
    ),
  EducationLevel_Preop = forcats::fct_relevel(
    EducationLevel_Preop, 
    "Up to Secondary Year 10",
    "Secondary - Year 12",
    "Post-secondary trade certificate or diploma",
    "Undergraduate degree",
    "Postgraduate degree"
    ),
  SmokingStatus_Preop = forcats::fct_relevel(
    SmokingStatus_Preop, 
    "Never smoked" ,
    "Non smoker for >12 months",
    "Non smoker for <12 months",
    "Current smoker"
    ),
  ActivityLevel_Preop = forcats::fct_relevel(
    ActivityLevel_Preop, 
    "Zero" ,
    "About 30 minutes",
    "About 1 hour",
    "About 2 hours",
    "More than 2 hours"
    )
  # across(
  #   matches("MODEMQ", ignore.case = TRUE) & ends_with("_Preop", ignore.case = TRUE),
  #   ~ forcats::fct_relevel(.x,
  #     "Not applicable",
  #     "Not at all likely",
  #     "Slightly likely",
  #     "Somewhat likely",
  #     "Very likely",
  #     "Extremely likely"
  #   )
  # )
  )
```

A predictor matrix was specified as per the *mice* package functions, to indicate which variables should be used to predict others. In this case the record identifier column was removed from the matrix. Imputations were performed for 20 iterations.

```{r}

predM <- mice::make.predictorMatrix(Mastersheet4)

# Switch off IDs from predicting
predM[,"TreatmentID"] <- 0 
predM["TreatmentID",] <- 0
predM[,"AccountType2"] <- 0 
predM["AccountType2",] <- 0

# Create a method vector
meth <- mice::make.method(Mastersheet4)

# Modified mice command including method specification
MasterImp <- mice::mice(
  Mastersheet4,
  maxit = 10,
  seed = 4218,
  m = 10,
  printFlag = FALSE,
  predictorMatrix = predM,
  method = meth
  )


```

```{r}
#| label: fig-density

DASHDens <- mice::densityplot(MasterImp, ~QDASH_TotalScore_Preop)

knitr::knit_print(DASHDens)
```

```{r}
#| label: fig-WORCstrip
#| fig-cap: "Stability of imputed variables over iterations for dataset"


plot(MasterImp)
```

A strip plot (Figure 4) were used to visually inspect the convergence of the imputation iterations against the original dataset.

# Analysis Results

## RECORD \[13\] Participants

```{epoxy}

The initial export from the registry returned {nrow(SnapshotComb)} records of all types. 

```

### RECORD \[13.1\] Treatment selection

A flow chart of individual treatment episodes (treatments) was generated using the *consort* package and prepared for display with the *knitr* package.

The diagram below summarises recruitment and categorisation of patients into the PRULO registry.

```{r}
#| label: fig-strobe
#| fig-cap: "Flowchart of extraction and followup of sample from the Registry"

STROBEPlot <- consort_plot(data = STROBEFlow,
                    orders = c(trialno = "Population",
                               exclusion1 = "Ineligible",
                               trialno = "Baseline Analysis",
                               exclusion2 = "Non-index",
                               subjid_dosed = "Analysed",
                               arm3 = "Cohort"
                    ),
                    side_box = c(
                      "exclusion1",
                      "exclusion2"
                    ),
                    allocation = "arm3",
                    cex = 0.7
)



knitr::knit_print(STROBEPlot)
```

The table below summarises patient diagnoses in the PRULO registry.

```{r}
#| label: tbl-diagnosis
#| tbl-cap: "Summary of diagnoses by ICD-10 code"

TableData <- Mastersheet2 |>
  mutate(
    ICD10 = stringr::str_extract(DiagnosisPrimary,"^[A-Za-z]+[0-9.]+")
  ) |> count(ICD10, sort = TRUE) |>
  slice_head(n = 5)

knitr::kable(TableData)


```

## RECORD \[14\] Patient characteristics

```{r}
#| label: tbl-characteristics
#| tbl-cap: "Summary of patient characteristics"

TablePatientChar <- Mastersheet4 |>
 dplyr::select(
    AgeAtInitialExam, 
    Sex2, 
    IndexSide,
    #Surgeon2,
    #BMI,
    BilateralStatus,
    EducationLevel_Preop,
    SmokingStatus_Preop,
    ActivityLevel_Preop,
    AlcoholConsumption_Preop,
    AccountType2
    ) |>
  tbl_summary(
    label = list(
    AgeAtInitialExam ~ "Age at Consult",
    #Surgeon2 ~ "Surgeon",
    #BMI ~ "Body Mass Index",
    BilateralStatus ~ "Bilateral",
    Sex2 ~ "Female",
    IndexSide ~ "Non-dominant",
    EducationLevel_Preop ~ "Education",
    SmokingStatus_Preop ~ "Smoking",
    ActivityLevel_Preop ~ "Activity",
    AlcoholConsumption_Preop ~ "Alcohol",
    AccountType2 ~ "Insurance"
    ),
    type = list(
    Sex2 ~ "dichotomous",
    IndexSide ~ "dichotomous"),
    value = list(
      Sex2 ~ "Female",
      IndexSide ~ "Non-dominant"),
    statistic = list(
      AgeAtInitialExam ~ "{mean} ({sd})",
      #BMI ~ "{mean} ({sd})",
      all_categorical() ~ "{p}% ({n})"),
    missing = "no") |>
  add_n() |>
  add_ci(statistic = list(all_categorical() ~ "{conf.low} - {conf.high}",
                          all_continuous() ~ "{conf.low} - {conf.high}")) |>
   add_stat_label(
    location = "row"
  ) |> modify_table_styling(
      columns = label,
      rows = label == "DVA",
      footnote = "DVA = Department of Veterans Affairs"
    ) |> modify_table_styling(
      columns = label,
      rows = label == "TAC",
      footnote = "TAC = Transport Accident Commission"
    )

gtsummary::as_flex_table(TablePatientChar)

```

Patient characteristics for cases are summarised in @tbl-characteristics.

## RECORD \[15\] Patient-reported outcome measures

The QuickDASH total score and WORC Normalised Index, as well as Question 3 of the Physical sub-scale of the WORC were visualised using the *ggdist* and *ggplot2* packages. Plots were arranged using the *patchwork* package.

```{r}
#| label: tbl-proms
#| tbl-cap: "Summary of patient-reported outcomes separated by Cohort"

Table4 <- tbl_summary(
  Mastersheet4 |> dplyr::select(
    QDASH_TotalScore_Preop,
    EQ5D5L_IndexScore_Preop,
    #MODEMQ1_Preop:MODEMQ6_Preop,
    Cohort
  ) |> mutate(
    QDASH_TotalScore_Preop = as.numeric(QDASH_TotalScore_Preop),
    EQ5D5L_IndexScore_Preop = as.numeric(EQ5D5L_IndexScore_Preop)
    ),
  by = Cohort
) |> add_overall() |> add_p()

gtsummary::as_flex_table(Table4)

```

## RECORD \[16\] Main results

The imputed datasets for QDASH and EQ5D5L were modeled with a linear model in *lm*

```{r}
#| label: tbl-QDASHfit
#| tbl-cap: "Pooled linear mixed effects model for QuickDASH"

QDASHfitUnadj <- with(
  MasterImp,
  exp = stats::lm(
    QDASH_TotalScore_Preop ~ Cohort
  )
                 )

QDASHfitimpUnadj <- tbl_regression(QDASHfitUnadj, tidy_fun = pool_and_tidy_mice,
               label = list( 
                            Cohort ~ "Diagnostic Group"
                            ),
               estimate_fun = function(x) style_number(x, digits = 2), 
               pvalue_fun = function(x) style_pvalue(x, digits = 3))  

gtsummary::as_flex_table(QDASHfitimpUnadj)


```

```{r}
#| label: tbl-EQ5Dfit
#| tbl-cap: "Pooled linear model for EQ5D"

EQ5DfitUnadj <- with(
  MasterImp,
  exp = stats::lm(
    EQ5D5L_IndexScore_Preop ~ Cohort
  )
                 )

EQ5DfitimpUnadj <- tbl_regression(EQ5DfitUnadj, tidy_fun = pool_and_tidy_mice,
               label = list( 
                            Cohort ~ "Diagnostic Group"
                            ),
               estimate_fun = function(x) style_number(x, digits = 2), 
               pvalue_fun = function(x) style_pvalue(x, digits = 3))  

gtsummary::as_flex_table(EQ5DfitimpUnadj)


```

```{r}
#| label: tbl-QDASHfitAdj
#| tbl-cap: "Pooled linear model for QuickDASH with adjustment"

QDASHfitAdj <- with(
  MasterImp,
  exp = stats::lm(
    QDASH_TotalScore_Preop ~ Cohort + AgeAtInitialExam + Sex2 + BilateralStatus + SMCQTotal + ActivityLevel_Preop + AlcoholConsumption_Preop + SmokingStatus_Preop
  )
                 )

QDASHfitimpAdj <- tbl_regression(
  QDASHfitAdj, 
  tidy_fun = pool_and_tidy_mice,
  show_single_row = c(
    "Sex2",
    "BilateralStatus"
  ),
  label = list(
    Cohort ~ "Diagnostic Group",
    AgeAtInitialExam ~ "Age at Consult",
    BilateralStatus ~ "Bilateral",
    Sex2 ~ "Female",
    SmokingStatus_Preop ~ "Smoking",
    ActivityLevel_Preop ~ "Activity",
    AlcoholConsumption_Preop ~ "Alcohol"
                 ),
  estimate_fun = function(x) style_number(x, digits = 2),
  pvalue_fun = function(x) style_pvalue(x, digits = 3))  

gtsummary::as_flex_table(QDASHfitimpAdj)


```

```{r}
#| label: tbl-EQ5DfitAdj
#| tbl-cap: "Pooled linear model for EQ5D with adjustment"

EQ5DfitAdj <- with(
  MasterImp,
  exp = stats::lm(
    EQ5D5L_IndexScore_Preop ~ Cohort + AgeAtInitialExam + Sex2 + BilateralStatus + SMCQTotal + ActivityLevel_Preop + AlcoholConsumption_Preop + SmokingStatus_Preop
  )
                 )

EQ5DfitimpAdj <- tbl_regression(
  EQ5DfitAdj, 
  tidy_fun = pool_and_tidy_mice,
  show_single_row = c(
    "Sex2",
    "BilateralStatus"
  ),
  label = list(
    Cohort ~ "Diagnostic Group",
    AgeAtInitialExam ~ "Age at Consult",
    BilateralStatus ~ "Bilateral",
    Sex2 ~ "Female",
    SmokingStatus_Preop ~ "Smoking",
    ActivityLevel_Preop ~ "Activity",
    AlcoholConsumption_Preop ~ "Alcohol"
                 ),
  estimate_fun = function(x) style_number(x, digits = 3),
  pvalue_fun = function(x) style_pvalue(x, digits = 3))  

gtsummary::as_flex_table(EQ5DfitimpAdj)


```

```{r}
#| label: tbl-postQDASH
#| tbl-cap: "Post-hoc comparisons between Cohorts for QuickDASH"

QDASHPost <- marginaleffects::avg_comparisons(
  QDASHfitAdj, 
  variables = list(Cohort = "pairwise"),
  type = "response"
  #re.form = NA
  ) 


knitr::kable(
  QDASHPost |> dplyr::select(-term),
  digits = c(
    0,2,2,2,2,2,3,2,2
  )
  )  

```

```{r}
#| label: tbl-postEQ5D
#| tbl-cap: "Post-hoc comparisons between Cohorts for EQ5D"

EQ5DPost <- marginaleffects::avg_comparisons(
  EQ5DfitAdj, 
  variables = list(Cohort = "pairwise"),
  type = "response"
  #re.form = NA
  ) 


knitr::kable(
  EQ5DPost |> dplyr::select(-term),
  digits = c(
    0,2,2,2,2,2,3,2,2
  )
  )  

```

```{r, Predictions}

QDASHPredict <-  marginaleffects::predictions(QDASHfitAdj)
EQ5DPredict <- marginaleffects::predictions(EQ5DfitAdj)

```

```{r}
#| label: tbl-QDASHimp
#| tbl-cap: "Summary of model-predicted QuickDASH by Cohort"


TableQDASHImp <- tbl_summary(
  QDASHPredict %>% dplyr::select(
    Cohort,
    QDASH_TotalScore_Preop
  ),
  by = Cohort,
  label = list(
    QDASH_TotalScore_Preop ~ "QuickDASH"
  ),
  statistic = list(all_continuous() ~ "{median} ({p25} - {p75})")
    )

gtsummary::as_flex_table(TableQDASHImp)
```

```{r}
#| label: tbl-EQ5Dimp
#| tbl-cap: "Summary of model-predicted EQ5D by Cohort"


TableEQ5Dsum <- tbl_summary(
  EQ5DPredict %>% dplyr::select(
    Cohort,
    EQ5D5L_IndexScore_Preop
  ),
  by = Cohort,
  label = list(
    EQ5D5L_IndexScore_Preop ~ "Index Score"
  ),
  statistic = list(all_continuous() ~ "{median} ({p25} - {p75})")
    )


gtsummary::as_flex_table(TableEQ5Dsum )

```

## RECORD \[17\] Sensitivity analyses

Does it make a difference if subgroups (adhesive capsulitis and glenohumeral osteoarthritis) are split from the general cohort. Regular expressions were used in the *stringr* package to identify diagnosis codes that match adhesive capsulitis or glenohumeral osteoarthritis.

```{r}

Mastersheet5 <- Mastersheet4 |> left_join(
  Mastersheet3 |> dplyr::select(
    CombID,
    DiagnosisPrimary,
    TreatmentID
  ),
  by = "TreatmentID"
) |> mutate(
  Cohort2 = case_when(
    str_detect(DiagnosisPrimary , "M75.0") ~ "Adhesive Capsulitis",
    str_detect(DiagnosisPrimary , "arthrop*|arthrosis") ~ "GHOsteoarthritis",
    .default = Cohort
  )
) |> relocate(
  Cohort2,
  .before = Cohort
)

```

```{r}
MasterSens1 <- Mastersheet5 |> dplyr::select(
  CombID,
  TreatmentID,
  AgeAtInitialExam,
  Sex2,
  BilateralStatus,
  AlcoholConsumption_Preop,
  SmokingStatus_Preop,
  ActivityLevel_Preop,
  StraightDist,
  SMCQTotal,
  Cohort2,
  QDASH_TotalScore_Preop,
  EQ5D5L_IndexScore_Preop,
  matches("modem", ignore.case = TRUE) & ends_with("preop", ignore.case = TRUE),
  AccountType2
) |> mutate(
  CompStatus = if_else(str_detect(AccountType2,"Work|DVA|TAC"),"Yes","No")
) |> dplyr::select(
  -AccountType2
)
```

```{r}

predM2 <- make.predictorMatrix(MasterSens1)

##Switch off UID from MI algorithm
predM2[,"TreatmentID"] <- 0 # Switch off ID from predicting
predM2["TreatmentID",] <- 0
predM2[,"CombID"] <- 0 # Switch off ID from predicting
predM2["CombID",] <- 0

MasterImp2 <- mice::mice(MasterSens1,
                       maxit = 10,
                       set.seed(4218),
                       m = 10,
                       printFlag = FALSE,
                       predictorMatrix = predM2)


```

```{r}


# Fit the lm model(s)
# 
QDASHfitimp2 <- with(MasterImp2,exp = lm(
    QDASH_TotalScore_Preop ~ Cohort2 + AgeAtInitialExam + Sex2 + BilateralStatus + SMCQTotal + ActivityLevel_Preop + AlcoholConsumption_Preop + SmokingStatus_Preop
  )
  )

```

```{r}
#| label: tbl-QDASHsens
#| tbl-cap: "Summary of linear model with multiple imputation for QuickDASH with expanded Cohort definitions."

QDASHfitimpsum2 <- tbl_regression(
  QDASHfitimp2, 
  tidy_fun = pool_and_tidy_mice, 
  show_single_row = c(
    "Sex2",
    "BilateralStatus"
  ),
  label = list(
    Cohort2 ~ "Diagnostic Group",
    AgeAtInitialExam ~ "Age at Consult",
    BilateralStatus ~ "Bilateral",
    Sex2 ~ "Female",
    SmokingStatus_Preop ~ "Smoking",
    ActivityLevel_Preop ~ "Activity",
    AlcoholConsumption_Preop ~ "Alcohol"
                 ),
  estimate_fun = function(x) style_number(x, digits = 2),
  pvalue_fun = function(x) style_pvalue(x, digits = 3))  

gtsummary::as_flex_table(QDASHfitimpsum2)


```

```{r}
#| label: tbl-QDASHsenspost
#| tbl-cap: "Post-hoc comparisons between modified cohorts for QuickDASH."

QDASHfitPost2 <- marginaleffects::avg_comparisons(
  QDASHfitimp2, 
  variables = list(Cohort2 = "pairwise"),
  type = "response"
  #re.form = NA
  )  

knitr::kable(
  QDASHfitPost2 |> dplyr::select(-term),
  digits = c(
    0,2,2,2,2,2,3,2,2
  )
  )

```

```{r}
#| label: tbl-EQ5Dsens
#| tbl-cap: "Summary of linear model with multiple imputation for EQ5D5L with expanded Cohort definitions."

# Fit the lm model(s)
# 
EQ5Dfitimp2 <- with(MasterImp2,exp = lm(
    EQ5D5L_IndexScore_Preop ~ Cohort2 + AgeAtInitialExam + Sex2 + BilateralStatus + SMCQTotal + ActivityLevel_Preop + AlcoholConsumption_Preop + SmokingStatus_Preop
  )
  )

EQ5Dfitimpsum2 <- tbl_regression(
  EQ5Dfitimp2, 
  tidy_fun = pool_and_tidy_mice,
  show_single_row = c(
    "Sex2",
    "BilateralStatus"
  ),
  label = list(
    Cohort2 ~ "Diagnostic Group",
    AgeAtInitialExam ~ "Age at Consult",
    BilateralStatus ~ "Bilateral",
    Sex2 ~ "Female",
    SmokingStatus_Preop ~ "Smoking",
    ActivityLevel_Preop ~ "Activity",
    AlcoholConsumption_Preop ~ "Alcohol"
                 ),
  estimate_fun = function(x) style_number(x, digits = 2),
  pvalue_fun = function(x) style_pvalue(x, digits = 3)) 

gtsummary::as_flex_table(EQ5Dfitimpsum2)


```

```{r}
#| label: tbl-EQ5Dsenspost
#| tbl-cap: "Post-hoc comparisons between modified cohorts for EQ5D"

EQ5DfitPost2 <- avg_comparisons(
  EQ5Dfitimp2, 
  variables = list(Cohort2 = "pairwise"),
  type = "response"
  #re.form = NA
  ) 

knitr::kable(
  EQ5DfitPost2 |> dplyr::select(-term),
  digits = c(
    0,2,2,2,2,2,3,2,2
  )
  )

```

# Discussion

## RECORD \[18\] Key Results

The minimal clinically important difference of the QuickDASH is purported to be 15.91 points [@franchignoni2014], the results show that while the effect of *Cohort* on QuickDASH at initial presentation may be significant, the differences between registry subgroups do not reach the MCID, even when the *General* cohort is broken into more specialised subgroups (adhesive capsulitis, glenohumeral osteoarthritis).

Nevertheless, the results demonstrate that varying shoulder pathology is associated with variations in baseline pain and function at initial presentation for orthopaedic review. Pathology-based cohorts in shoulder orthopaedic registries are important to define to collect cohort-relevant outcomes, however a foundation PROMs selection should be considered.

## RECORD \[19\] Limitations

| Limitation | Impact | Mitigation | Interpretation |
|------------------|------------------|------------------|-------------------|
| Diagnosis coding | Classification bias |  |  |
| Model specification (covariates) | Risk that model is misspecified | DAG-based approach to covariate selection | Future work should be directed to building better quality evidence for covariate selection |
| PROMs selection | Responsiveness across broad spectrum of shoulder pathologies | Validated, general-purpose upper limb score and | QuickDASH may not be as responsive to some pathologies included in the analysis (General cohort) |
| Geographic constraint | Limits generalisability to regional \| rural patient population | The setting is close to a capital city \| metro but the patient population is somewhat distinct | The results should be interpreted with some caution when applying to the metropolitan patient context |

## RECORD \[20\] Interpretation

## RECORD \[21\] Generalisability

See limitations. Baseline scores are known to vary based on country and region [@ardebol2023], although these results should be interpreted with caution given the normalisation technique used over varying scores.

# Other Information

## RECORD \[22\] Funding

Partial funding of the PRULO Registry is provided by Depuy-Mitek (Johnson and Johnson Medical Pty Ltd). Funding arrangements for the PRULO registry are further detailed in the protocol [@scholes2023]

### RECORD \[22.1\] Accessibility

<!--# Authors should provide information on how to access any supplemental information such as the study protocol, raw data, or programming code. -->

Access to study protocol and programming code are provided through this report.

# References
